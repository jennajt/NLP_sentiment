{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711a5639-8d4f-4f60-b921-8b13869887ea",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99837db-0ccb-467d-8726-3c0f01d10fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e417c45-b7bd-4110-b375-30fd5fb33f52",
   "metadata": {},
   "source": [
    "## Get Model Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ecd525e9-cdd5-466e-bc0f-92d5812c13a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#MODEL1 = \"cardiffnlp/twitter-roberta-base-emoji\"\n",
    "MODEL2 = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "MODEL3 = \"cardiffnlp/twitter-roberta-base-hate\"\n",
    "MODEL4 = \"cardiffnlp/twitter-roberta-base-irony\"\n",
    "MODEL5 = \"cardiffnlp/twitter-roberta-base-offensive\"\n",
    "MODEL6 = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "#model1 = AutoModelForSequenceClassification.from_pretrained(MODEL1)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL2)\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(MODEL3)\n",
    "model4 = AutoModelForSequenceClassification.from_pretrained(MODEL4)\n",
    "model5 = AutoModelForSequenceClassification.from_pretrained(MODEL5)\n",
    "model6 = AutoModelForSequenceClassification.from_pretrained(MODEL6)\n",
    "\n",
    "#tokenizer1 = AutoTokenizer.from_pretrained(MODEL1)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(MODEL2)\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(MODEL3)\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(MODEL4)\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(MODEL5)\n",
    "tokenizer6 = AutoTokenizer.from_pretrained(MODEL6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c874b405-3ac2-4f0c-9758-ebfd476efc89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping_link1 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emoji/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link1) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels1 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link2 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/emotion/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link2) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels2 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link3 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/hate/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link3) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels3 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link4 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/irony/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link4) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels4 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link5 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/offensive/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link5) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels5 = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "mapping_link6 = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link6) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels6 = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830d159-8c48-4e13-a12f-b90e4de09134",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1dd2f629-98a4-495e-bd09-81b16b03c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"PATH TO RAW CSV FILE FROM SNSCRAPE\")\n",
    "#tweets_df = pd.DataFrame(data)\n",
    "#tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fd471-45c4-4c9a-98da-e635b963e482",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c212fa36-8692-4211-b111-3d491cbab6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    tweets = [i for i in df[\"Text\"]]\n",
    "    preprocessed_tweets = []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        new_text=[]\n",
    "        \n",
    "        for t in tweet.split(\" \"):\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            t = 'http' if '\\nhttp' in t else t \n",
    "            new_text.append(t)\n",
    "            \n",
    "        preprocessed_tweets.append(\" \".join(new_text))\n",
    "    return preprocessed_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed93d404-913e-4c8c-be8a-00847898c599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def method2_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer2(text, return_tensors='pt')\n",
    "        output = model2(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"anger\": [], \"sadness\": [], \"optimism\": [], \"joy\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels2[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"joy\"] = results[\"joy\"]\n",
    "        dofi[\"optimism\"] = results[\"optimism\"]\n",
    "        dofi[\"anger\"] = results[\"anger\"]\n",
    "        dofi[\"sadness\"] = results[\"sadness\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0a13a3f-2f9b-4e5f-a46d-a417a01c50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method3_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer3(text, return_tensors='pt')\n",
    "        output = model3(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"not-hate\": [], \"hate\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels3[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"not-hate\"] = results[\"not-hate\"]\n",
    "        dofi[\"hate\"] = results[\"hate\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec268958-f846-4bea-a2ef-c55f96df3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method4_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer4(text, return_tensors='pt')\n",
    "        output = model4(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"non_irony\": [], \"irony\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels4[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"not_irony\"] = results[\"non_irony\"]\n",
    "        dofi[\"irony\"] = results[\"irony\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ffa69053-e8be-4c2b-83aa-3754f4f0adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method5_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer5(text, return_tensors='pt')\n",
    "        output = model5(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"not-offensive\": [], \"offensive\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels5[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"not_offensive\"] = results[\"not-offensive\"]\n",
    "        dofi[\"offensive\"] = results[\"offensive\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a04e811-c36b-4778-8be6-093e07a7cbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def method6_processing(df, prep_df, append=False):\n",
    "    score_list = []\n",
    "    dofi = df\n",
    "    \n",
    "    for text in prep_df:\n",
    "        encoded_input = tokenizer6(text, return_tensors='pt')\n",
    "        output = model6(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        score_list.append(scores)\n",
    "\n",
    "    ranking = np.argsort(score_list[0])\n",
    "    ranking = ranking[::-1]\n",
    "    results = {\"positive\": [], \"neutral\": [], \"negative\": []}\n",
    "\n",
    "    for count, tweet_score in enumerate(score_list):\n",
    "        for i in range(tweet_score.shape[0]):\n",
    "            l = labels6[ranking[i]]\n",
    "            s = tweet_score[ranking[i]]\n",
    "            results[f\"{l}\"].append(np.round(float(s), 4))\n",
    "\n",
    "    if append == True:\n",
    "        \n",
    "        dofi[\"positive\"] = results[\"positive\"]\n",
    "        dofi[\"neutral\"] = results[\"neutral\"]\n",
    "        dofi[\"negative\"] = results[\"negative\"]\n",
    "        \n",
    "        return dofi\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "61d78ff3-dca7-4e03-b9bf-b45073ab4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_RoBERTa_processing(df):\n",
    "    prep_df = preprocess(df)\n",
    "    \n",
    "    m2 = method2_processing(df, prep_df, True)\n",
    "    m3 = method3_processing(m2, prep_df, True)\n",
    "    m4 = method4_processing(m3, prep_df, True)\n",
    "    m5 = method5_processing(m4, prep_df, True)\n",
    "    m6 = method6_processing(m5, prep_df, True)\n",
    "    \n",
    "    return m6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c2a43-5802-40a8-a3c2-04c516aa8f7d",
   "metadata": {},
   "source": [
    "## Process Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ec7e689-24ba-419c-9006-df1b3323b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"joy\"] = results[\"joy\"]\n",
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"optimism\"] = results[\"optimism\"]\n",
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"anger\"] = results[\"anger\"]\n",
      "/var/folders/x7/ljbh3tfd75bf71kcpdq1b5pw0000gn/T/ipykernel_44907/1316031096.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dofi[\"sadness\"] = results[\"sadness\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Like Count</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>anger</th>\n",
       "      <th>sadness</th>\n",
       "      <th>not-hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>not_irony</th>\n",
       "      <th>irony</th>\n",
       "      <th>not_offensive</th>\n",
       "      <th>offensive</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-07 02:12:00+00:00</td>\n",
       "      <td>1533995157858795525</td>\n",
       "      <td>Biden blasted for ‘monumental disaster’ as 11,...</td>\n",
       "      <td>Daily_Express</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.4864</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.6031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-06 11:40:05+00:00</td>\n",
       "      <td>1533775732345823232</td>\n",
       "      <td>More than 45,000 Americans apply to sponsor Uk...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>17</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-06-05 03:29:56+00:00</td>\n",
       "      <td>1533289994584002561</td>\n",
       "      <td>Anger as hundreds of refugee children from Ukr...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.8237</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-04 00:40:42+00:00</td>\n",
       "      <td>1532885015918411777</td>\n",
       "      <td>More than 10,000 migrants have already crossed...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.2478</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.3815</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-03 23:30:07+00:00</td>\n",
       "      <td>1532867253988884485</td>\n",
       "      <td>This week marked one hundred days since Russia...</td>\n",
       "      <td>MailOnline</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.7448</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>0.2920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Datetime             Tweet Id  \\\n",
       "0           0  2022-06-07 02:12:00+00:00  1533995157858795525   \n",
       "1           1  2022-06-06 11:40:05+00:00  1533775732345823232   \n",
       "2           2  2022-06-05 03:29:56+00:00  1533289994584002561   \n",
       "3           3  2022-06-04 00:40:42+00:00  1532885015918411777   \n",
       "4           4  2022-06-03 23:30:07+00:00  1532867253988884485   \n",
       "\n",
       "                                                Text       Username  \\\n",
       "0  Biden blasted for ‘monumental disaster’ as 11,...  Daily_Express   \n",
       "1  More than 45,000 Americans apply to sponsor Uk...     MailOnline   \n",
       "2  Anger as hundreds of refugee children from Ukr...     MailOnline   \n",
       "3  More than 10,000 migrants have already crossed...     MailOnline   \n",
       "4  This week marked one hundred days since Russia...     MailOnline   \n",
       "\n",
       "   Like Count     joy  optimism   anger  sadness  not-hate    hate  not_irony  \\\n",
       "0           3  0.0147    0.0611  0.4864   0.4378    0.8953  0.1047     0.2895   \n",
       "1          17  0.3515    0.4267  0.1159   0.1059    0.9821  0.0179     0.0820   \n",
       "2          16  0.0090    0.0191  0.8268   0.1451    0.9758  0.0242     0.1763   \n",
       "3          17  0.0449    0.2478  0.1538   0.5535    0.8377  0.1623     0.3815   \n",
       "4          16  0.3370    0.1641  0.3206   0.1783    0.9676  0.0324     0.2552   \n",
       "\n",
       "    irony  not_offensive  offensive  positive  neutral  negative  \n",
       "0  0.7105         0.7107     0.2893    0.0131   0.3838    0.6031  \n",
       "1  0.9180         0.8914     0.1086    0.2166   0.7758    0.0076  \n",
       "2  0.8237         0.8000     0.2000    0.0048   0.1251    0.8701  \n",
       "3  0.6185         0.7943     0.2057    0.0370   0.8017    0.1613  \n",
       "4  0.7448         0.7987     0.2013    0.0175   0.6905    0.2920  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = tweet_RoBERTa_processing(tweets_df)\n",
    "processed_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
